[TOC]



### JDK基础模块

参考源码分析：[jdk1.8-source](https://github.com/zcswl7961/jdk1.8-source)

- [x] ReentrantLock   [逐行源码分析AbstractQueuedSynchronizer(AQS)中ReentrantLock的源码实现](http://www.zcswl7961.com/index.php/2020/12/03/abstractqueuedsynchronizer/)
- [x] CountDownLatch [逐行源码分析AbstractQueuedSynchronizer(AQS)中CountDownLatch的源码实现](http://www.zcswl7961.com/index.php/2020/12/09/aqs-countdownlatch/)
- [x] Semaphore [逐行源码分析AbstractQueuedSynchronizer(AQS)中Semaphore的源码实现](http://www.zcswl7961.com/index.php/2020/12/09/aqs-semaphore/)
- [x] HashMap [Java包-HashMap](https://www.processon.com/view/link/60139ed4079129652cdf9c93)
- [x] TreeMap [Java包-TreeMap](https://www.processon.com/view/link/60139ed4079129652cdf9c93)
- [x] LinkedHashMap [Java包-LinkedHashMap](https://www.processon.com/view/link/60139ed4079129652cdf9c93)
- [x] ConcurrentHashMap [Java包-ConcurrentHashMap](https://www.processon.com/view/link/60139ed4079129652cdf9c93)
- [x] Executor [线程池](https://www.processon.com/view/link/60139f617d9c08426cf87106)
- [x] ThreadPoolExecutor [线程池-ThreadPoolExecutor](https://www.processon.com/view/link/60139f617d9c08426cf87106)
- [x] ScheduledThreadPoolExecutor [线程池-ScheduledThreadPoolExecutor](https://www.processon.com/view/link/60139f617d9c08426cf87106)
- [x] ArrayList [Java包-ArrayList](https://www.processon.com/view/link/60139f617d9c08426cf87106)
- [x] LinkedArrayList [Java包-LinkedList](https://www.processon.com/view/link/60139f617d9c08426cf87106)
- [x] Queue [Java包-Queue和Deque](https://www.processon.com/view/link/60139ed4079129652cdf9c93)
- [x] ClassLoader#getResource Class#getResource [Class和ClassLoader关于getResource()，getResourceAsStream()的区别](https://blog.csdn.net/zcswl7961/article/details/103831231)
- [x] Throwable [Java包-Throwable体系](https://www.processon.com/view/link/60139ed4079129652cdf9c93)
- [x] ServiceLoader SPI [Java包-ServiceLoader](https://www.processon.com/view/link/60139ed4079129652cdf9c93)
- [x] Reference 引用类型 [Java包-Reference](https://www.processon.com/view/link/60139ed4079129652cdf9c93)
- [x] ThreadLocal [ThreadLocal的内存泄漏问题](https://www.zcswl7961.com/index.php/2021/02/03/threadlocal/) [一个面试进行的ThreadLocal源码深入分析](https://blog.csdn.net/zcswl7961/article/details/100769425?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161249075716780261973706%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=161249075716780261973706&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_v1~rank_blog_v1-1-100769425.pc_v1_rank_blog_v1&utm_term=ThreadLocal&spm=1018.2226.3001.4450)
- [x] Thread [线程](https://www.processon.com/view/link/60139f617d9c08426cf87106)



#### LinkedHashMap

​	1，LinkedHashMap是基于HashMap的基础上进行实现

​	2，插入的字段封装成了自己设置的Entry，并且加了一个before 和after，表示当前数据链接的前一个值和后一个值（双端链表）

​	插入的时候都是插入到链表的尾部：

​	**LinkedHashMap构造函数有一个参数：accessOrder：默认的情况下时false：表示LinkedHashMap是按照对应的插入顺序 true：表示访问顺序，如果一个值被访问了之后，会插入到链表的最后面，链表最前面的值表示都是最近未访问的值**

​	使用LinkedHashMap可以作为LRU缓存淘汰算法工具：

```
/**
 * LRU 最近最少使用的操作
 * LinkedHashMap 双端链表的方式
 * @author zhoucg
 * @date 2021-04-07 16:17
 */
public class LRU extends LinkedHashMap<Integer, Integer> {
    private int capacity;

    public LRU(int capacity) {
        super(capacity, 0.75f, true);
    }

    public int get(int key) {
        return super.getOrDefault(key, -1);
    }

    public void put(int key, int value) {
        super.put(key,value);
    }

    @Override
    protected boolean removeEldestEntry(Map.Entry<Integer, Integer> eldest) {
        return size() > capacity;
    }
}
```

#### HashMap

​	HashMap的内部的数据结构：数组+链表（链表长度大于8的时候会红黑树）

​	HashMap源码分析是一个很值得分析的点，

##### 1，为什么HashMap的长度是2的n次幂

​	核心得原因就是：**保持hashcode的散列，同时防止hash冲突**  

​	[博客原理](https://www.cnblogs.com/zxporz/p/11204233.html)

这是一个很好得问题，需要去了解出HashMap取位置的算法操作，以及其内部的核心算法：  
**HashMap根据指定的key取hash值得操作：**  

```
return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
```

**HashMap取对应数组槽得算法：**  

```
tab[i = (n - 1) & hash])
```

**HashMap是如何将对应得key存入到指定得数组中（找槽位）**

首先HashMap会根据传入得key值，重新计算出新得hashcode值，计算方法为：  
```
return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
```
即：**如果传入得key为null，返回得hashCode为0**【这个是特殊情况】  
	1，首先会将k得原始得hashcode值无符号得右移16位，即返回的hashcode值（int） 低16位存储的是原hash值得高16位  
	2，然后在和原来的hashcode进行亦或操作。【亦或操作即相同取0， 相反取1】  
	3，**亦或的操作即：保留原来hashcode值得高16位，新得hashcode值得低16位实际上是由原来得高16位与低16位进行亦或得到的，即：可以将高低位二进制特征混合起来（我觉得这个词说的很好）**  
<**为什么要进行亦或操作而不是其他**>
 **异或运算能更好的保留各部分的特征，如果采用&运算计算出来的值会向0靠拢，采用|运算计算出来的值会向1靠拢**

然后，获得的新的hash值会进行：
```
(p = tab[i = (n - 1) & hash])
```
操作获取对应的数组的槽位；

从这个问题也能看出来，**为什么hashMap的数组长度为2的n次幂**

​	**1、为了让哈希后的结果更加均匀**  
​	**2、可以通过位运算e.hash & (newCap - 1)来计算，a % (2^n) 等价于 a & (2^n - 1)  ，位运算的运算效率高于算术运算，原因是算术运算还是会被转化为位运算**


《**这是表面原因，%len和&(len-1)效率问题其实差距不大，&也就是%的4倍左右的差距；2n的核心原因是hash函数的源码中右移了16位让低位保留高位信息，原本的低位信息不要，那么进行&操作另一个数低位必须全是1，否则没有意义，所以len必须是2n，也就是要尽量把数据分配均匀！**》【讲道理这个解释不错】

**终目的还是为了让哈希后的结果更均匀的分部，减少哈希碰撞，提升hashmap的运行效率**

##### 2，HashMap源码的内部实现逻辑

​		**核心成员变量：**

​			modCount:表示对HashMap结构的修改次数：包括新增，删除，修改；同时也能够检测出HashMap的快速失败机制：

​								什么是fail-fast机制：在使用迭代器对集合对象进行遍历的时候，如果 A 线程正在对集合进行遍历，此时 B 线程对集合																	进行修改（增加、删除、修改），或者 A 线程在遍历过程中对集合进行修改，都会导致 A 线程抛																	出 ConcurrentModificationException 异常。

​			threshold：扩容阈值：使用table（数组）长度length * loadFactor（负载因子）计算得出

​			size：表示当前HashMap中存放的k，v的总数

​		**插入机制：**

​		1,  查询对应的槽位

​		2，判断槽位是否存在对应的值，如果不存在，直接存入table数组，如果存在，
​		3，判断是否为TreeNode（红黑树），插入红黑树节点中，
​		4，如果为普通链表，插入指定链表尾部【同时判断链表长度是否大于8，链表变成红黑树】

​		**链表变成红黑树机制**

​			**[接着上面插入机制的第四步]**如果链表的长度达到固定的：**TREEIFY_THRESHOLD 8** 的时候，此时会将链表转换成红黑树

​		**扩容机制**

​			当当前HashMap中的size >threshold时，进行扩容操作

​			1，获取对应的oldCap【原始槽位数】，和oldThr【原始扩容阈值】

​			2, 计算newCap（oldCap<< 1 即*2），对于oldCap<16, newThr=newCap * threshold，对于oldCap>=16, newThr = oldThr << 1 即乘2

​			3，新建一个newCap大小的【Node<K,V>[] table】

​			4,   遍历原始的table

​				<1>如果指定槽位上有数据，并且不为链表形式，直接通过hash & (newCap-1) 获取新table的槽位，置之
​				<2>如果指定槽位上有数据，并且为TreeNode(红黑树)，通过((TreeNode<K,V>)e).split(this, newTab, j, oldCap);操作【这个还没研究】该操作会将对应的树形结构进行退化，如果退化之后的TreeNode的节点个数小于UNTREEIFY_THRESHOLD【6】会将TreeNode红黑树退化成链表
​				<3>如果指定槽位上有数据，并且为链表形式，此时，旧数组上的数据会通过e.hash & oldCap是否等于0
​       			**如果为0：表示该头节点放到新数组的索引位置等于其旧数组存放的索引位置：（这个算法过于牛批，真的）
​        				验证思路：**
​       				【(h = key.hashCode()) ^ (h >>> 16)】 & 2n次幂
​        				如果e.hash & (oldCap - 1) = e.hash & (2oldCap - 1) 那么一定是e.hash & oldCap == 0
​       			**如果不为0：表示该头节点放到新数组时的索引位置等于其旧数组时的索引位置再加上旧数组长度，**

##### 3，为什么HashMap的加载因子是0.75，链表变成红黑树的阈值是8

​		这个问题，在HashMap的官方文档中有对应的解释

> ```
> * Ideally, under random hashCodes, the frequency of
> * nodes in bins follows a Poisson distribution
> * (http://en.wikipedia.org/wiki/Poisson_distribution) with a
> * parameter of about 0.5 on average for the default resizing
> * threshold of 0.75, although with a large variance because of
> * resizing granularity. Ignoring variance, the expected
> * occurrences of list size k are (exp(-0.5) * pow(0.5, k) /
> * factorial(k)). The first values are:
> *
> * 0:    0.60653066
> * 1:    0.30326533
> * 2:    0.07581633
> * 3:    0.01263606
> * 4:    0.00157952
> * 5:    0.00015795
> * 6:    0.00001316
> * 7:    0.00000094
> * 8:    0.00000006
> * more: less than 1 in ten million
> ```

​		即核心的含义就是，事实上，在随机hashcode码中，节点出现的频率在hash桶中遵循泊松分布，同时给出了桶中元素个数和概率的对照表。

​		即基于0.75的加载因子考虑的情况下（带入到泊松分布算法中），最终计算的结果会发现，对于hash桶中的一个桶出现8个节点的概率会很低。

​		这个也解释了为什么加载因子为0.75的情况下，链表转成红黑树的阈值是8

​		[HashMap的泊松分布](https://blog.csdn.net/weixin_43883685/article/details/109809049)

​		**为什么HashMap的加载因子是：0.75，这个问题官方给定的解释是：**

> ```
> * <p>As a general rule, the default load factor (.75) offers a good
> * tradeoff between time and space costs.  Higher values decrease the
> * space overhead but increase the lookup cost (reflected in most of
> * the operations of the <tt>HashMap</tt> class, including
> * <tt>get</tt> and <tt>put</tt>).  The expected number of entries in
> * the map and its load factor should be taken into account when
> * setting its initial capacity, so as to minimize the number of
> * rehash operations.  If the initial capacity is greater than the
> * maximum number of entries divided by the load factor, no rehash
> * operations will ever occur.
> ```

​		**一般来说，默认的加载系数(0.75)提供了一个很好的选择时间和空间成本的权衡。较高的数值会降低空间开销，但增加查找成本(反映在大多数 `HashMap`类的操作，包括`get` and `put`)…**

​		关于泊松分布可以参考：[泊松分布](http://www.ruanyifeng.com/blog/2015/06/poisson-distribution.html#comment-356111)

#### ConcurrentHashMap

​		1，ConcurrentHashMap对应的key和value都不能为null，这一点和HashMap不相同

​		2，对于ConcurrentHashMap而言，其内部的数据结构和HashMap一致：数组+链表+红黑树

​		3，对于HashMap而言，是有对应fail-fast机制，但是对于ConcurrentHashMap而言，如何解决？

​				解答：ConcurrentHashMap是不存在对应的fail-fast机制，相反，它是fail-safe（即：安全失败），

​				在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。

##### 1，ConcurrentHashMap的size获取

​		先尝试通过cas更新baseCount计数

​		如果多线程竞争激烈，某些线程 CAS 失败，那就 CAS 尝试将 cellsBusy 置 1，成功则可以把 baseCount 变化的次数暂存到一个数组 			counterCells 里，后续数组 counterCells 的值会加到 baseCount 中。
​		如果 cellsBusy 置 1 失败又会反复进行 CAS baseCount 和 CAS counterCells 数组。

​		**重点：**

​				1，首先，ConcurrentHashMap中的baseCount存放的是未发生cas锁失败的记录总数

​				2，当尝试cas修改baseCount失败之后，实际上会将当前失败的次数存储在countCells数组中，所以CountCells存放 的都是value为1的CounterCell对象，而这些对象是因为在CAS更新baseCounter值时，由于高并发而导致失败，最终将值保存到CounterCell中，放到counterCells里。这也就是为什么sumCount()中需要遍历counterCells数组，sum累加CounterCell.value值了。

##### 2，ConcurrentHashMap的并发协助扩容机制

​		[ConcurrentHashMap的并发协助扩容机制](https://www.cnblogs.com/FondWang/p/12142149.html)

### 数据库

#### Mysql中的B树和B+树的区别

​		[一文彻底搞懂MySQL基础：B树和B+树的区别](https://blog.csdn.net/a519640026/article/details/106940115/)

​		B树具有以下的特点：

​				所有键值分布在整颗树中（索引值和具体data都在每个节点里）；

​				任何一个关键字出现且只出现在一个结点中；

​				搜索有可能在非叶子结点结束（最好情况O(1)就能找到数据）；

​				在关键字全集内做一次查找,性能逼近二分查找；

​		B+树是B树的变体，也是一种多路搜索树，它于B树的不同之处在于：

​				所有关键字存储在叶子节点出现,内部节点(非叶子节点并不存储真正的 data)

​				为所有叶子结点增加了一个链指针

#### Mysql的主从复制，以及Mysql的binlog主从复制延迟的原因

Mysql的binlog日志

设置binlog
log_bin=mysql_bin
log_bin_index=mysql_bin.index
其内部会在指定的binlog目录中生成对应的mysql_bin.xxxx01编号对应的binlog日志文件

sync_binlog=10
sync_binlog=0，当事务提交之后，MySQL不做fsync之类的磁盘同步指令刷新binlog_cache中的信息到磁盘，而让Filesystem自行决定什么时候来做同步，或者cache满了之后才同步到磁盘。
sync_binlog=n，当每进行n次事务提交之后，MySQL将进行一次fsync之类的磁盘同步指令来将binlog_cache中的数据强制写入磁盘。 



Mysql的binlog日志类型

**STATEMENT：基于SQL语句的复制(statement-based replication, SBR)**
             STATEMENT是基于sql语句级别的binlog,每一条修改数据的sql都会被保存到binlog里

**ROW:基于行的复制(row-based replication, RBR)**
             ROW是基于行级别的,他会记录每一行记录的变化,就是将每一行的修改都记录到binlog里面,记录的非常详细，但sql语句并没有在binlog里,在replication里面也不会因为存储过程触发器等造成Master-Slave数据不一致的问题,但是有个致命的缺点日志量比较大.由于要记录每一行的数据变化,当执行update语句后面不加where条件的时候或alter table的时候,产生的日志量是相当的大。

**MIXED:混合式的模式**



**statement模式的优缺点：**
1,binlog日志文件小，并且可读性好，binlog中包含了所有数据库修改信息，可以据此来审核数据库的安全等情况binlog可以用于实时的还原，而不仅仅用于复制，
2,核心缺点是并不能记录所有的Update语句，比如UUID(),FOUND_ROWS() 其中INSERT...UPDATE会产生更多的行级锁



**row模式的优缺点：**

优点： binlog中可以不记录执行的sql语句的上下文相关的信息，仅需要记录那一条记录被修改成什么了。所以row的日志内容会非常清楚的记录下每一行数据修改的细节。而且不会出现某些特定情况下的存储过程，或function，以及trigger的调用和触发无法被正确复制的问题.

缺点:所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，这样可能会产生大量的日志内容。



**Mysql的主从复制的原理**

1，MySQL主从复制的原理是基于binlog日志

mysql的主从复制都是单线程的操作，主库对所有DDL和 DML产生binlog，binlog是顺序写，所以效率很高，slave的Slave_IO_Running线程到主库取日志，效率很比较高，下一步， 问题来了，slave的Slave_SQL_Running线程将主库的DDL和DML操作在slave实施。DML和DDL的IO操作是随即的，不是顺 序的，成本高很多，还可能可slave上的其他查询产生lock争用，由于Slave_SQL_Running也是单线程的，所以一个DDL卡主了，需要 执行10分钟，那么所有之后的DDL会等待这个DDL执行完才会继续执行，这就导致了延时。有朋友会问：“主库上那个相同的DDL也需要执行10分，为什 么slave会延时？”，答案是master可以并发，Slave_SQL_Running线程却不可以。

**Mysql主从数据库同步延迟是怎么产生的？**

当主库的TPS并发较高时，产生的DDL数量超过slave一个sql线程所能承受的范围，那么延时就产生了，当然还有就是可能与slave的大型query语句产生了锁等待。读写锁的竞争问题，都会导致对应的同步延迟问题。

**Mysql数据库主从同步延迟解决方案**

最简单的减少slave同步延时的方案就是在架构上做优化，尽量让主库的DDL快速执行。还有就是主库是写，对数据安全性较高，比如 **sync_binlog=1，innodb_flush_log_at_trx_commit = 1** 之类的设置，而slave则不需要这么高的数据安全，完全可以讲sync_binlog设置为0或者关闭binlog，innodb_flushlog也 可以设置为0来提高sql的执行效率。另外就是使用比主库更好的硬件设备作为slave。

mysql-5.6.3已经支持了多线程的主从复制。



#### Mysql如何分页查询获取最后几页的数据

1， 直接使用mysql 提供的limit n， m语法进行分页：SELECT * FROM 表名称 LIMIT M,N
这种写法只适用于数据量比较少的情况，缺点就是在查询表的某位页数的时候，实际上会导致全表扫描，从而性能很低

2，使用order by 字段 ，并且order by的字段必须设置索引

3，根据对应的主键或者唯一索引，利用索引进行查询：（必须要保证对应的主键id或者唯一id连续）
SELECT * FROM 表名称 WHERE id_pk > (pageNum*10) LIMIT M

4，把limit偏移量限制低于某个数。。超过这个数等于没数据，我记得alibaba的dba说过他们是这样做的（优化页面性能）



#### Mysql中的MVCC和间隙锁的区别？

**MVCC是一种用来解决读-写冲突的无锁并发控制**

**非唯一索引下的范围查询会触发对应的间隙锁**

对一个未唯一索引的更新操作，会引发另一个事务无法插入当前索引

[[Innodb中的事务隔离级别和锁的关系](https://tech.meituan.com/2014/08/20/innodb-lock.html)](https://tech.meituan.com/2014/08/20/innodb-lock.html)

Mysql中的快照读和当前读的区别：

快照读：（就是select *）

​		select * from table ….;

当前读：（特殊的读操作，插入/更新/删除操作，属于当前读，处理的都是当前的数据，需要加锁）

​		select * from table where ? lock in share mode;

​		select * from table where ? for update;
​		insert;
​		update ;
​		delete;

事务的隔离级别实际上都是定义了当前读的级别，MySQL为了减少锁处理（包括等待其它锁）的时间，提升并发能力，引入了快照读的概念，使得select不用加锁。而update、insert这些“当前读”，就需要另外的模块来解决了。

**为了解决当前读中的幻读问题，Mysql事务使用了Next-key锁**



#### mysqlbinlog日志和redolog日志写入机制

通过两阶段提交的策略：

1. 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2
这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内
存，然后再返回。
2. 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的
一行数据，再调用引擎接口写入这行新数据。
3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo
log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。
4. 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。
5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状
态，更新完成。



### 网络

#### TCP三次握手/四次挥手机制

[TCP三次握手详解及释放连接过程](https://www.cnblogs.com/kaleidoscope/p/9701117.html)

[知乎讲解：TCP](https://www.zhihu.com/question/271701044)

### Redis

#### redis的数据结构

​		redis的内部数据结构分为：简单动态字符（SDS），字典（Dict），链表，压缩链表，跳跃表（skipList，zset，有序集合对象内部的数据结果），整形集合

​		[Redis内部分析](https://www.cnblogs.com/hunternet/p/9957913.html)【个人认为老哥的这个一些列博客讲的很是牛批】

redis常用的数据结构有哪些，内部是使用的底层数据结构分别是哪些？

​		字符串String: 	SDS, 整形集合（int）

​		哈希（hash）：字典，压缩链表

​		列表（list）：链表，压缩链表

​		集合（Set）：字典，整形集合（int）

​		有序列表: 压缩链表，跳跃表

#### redis的持久化机制

[**Redis提供的持久化机制**](https://www.cnblogs.com/xingzc/p/5988080.html)

​		RDB：

​				RDB 持久化方式能够在指定的时间间隔能对你的数据进行快照（snapshotting）存储，将内存中的数据不断写入二进制文件中，默认文件dump.rdb，可配置Redis在n秒内如果超过m个key被修改就自动保存快照。（性能高，但是可能会出现数据丢失）
例
save 900 1 #900秒内如果超过1个key被修改，则发起快照保存。
save 300 10 #300秒内如果超过10个key被修改，则快照保存。

RDB持久化只会周期性的保存数据，在未触发下一次存储时服务宕机，就会丢失增量数据。当数据量较大的情况下，fork子进程这个操作很消耗cpu，可能会发生长达秒级别的阻塞情况。

​		AOF：

​				AOF（Append-only file） 持久化方式记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据,AOF命令以redis协议追加保存每次写的操作到文件末尾.Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大。（类似于MySql的日志方式，记录每次更新的日志）（性能低，但是数据完整）



#### redis的事务

redis中的事务
事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。（这个redis似乎是能够去影响的）
事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。

Redis的事务的本质是通过MULTI, EXEC, WATCH等一组命令的集合

multi:开启一个事务

exec：表示执行事务

watch：命令是 watch keys 【监视指定的key。如果exec执行之前已经监视了某些key，如果key被另一个客户端修改对应的值，则execu对应的事务队列讲不会执行】

DISCARD：清空对应的事务中的commond队列，恢复连接状态（注意这个命令必须再multi之后执行【exec之前】），并且也能够清除对应的watch
了解了Redis事务机制后，我们继续看如何使用命令实现事务。



**redis的事务就是一致性，顺序性，排他性的执行一个队列中的命令**

**redis事务中出错怎么办？**

常见的错误：
	1，命令可能存在语法错误，进入队列的命令有误，比如参数数量错误，错误的命令名称
	2，执行EXEC运行时候时出错，比如给一个list类型的变量 执行incr + 1，这样的命令语法上没问题，只有在运行的时候才能发行

对于第一种错误，客户端会在EXEC调用之前检测， 通过检查排队命令的状态回复，如果命令使用QUEUED进行响应，则它已正确排队；否则Redis将返回错误。
对于第二种错误，服务端会记住在累积命令期间发生的错误，当EXEC命令调用时，将拒绝执行事务，并返回这些错误，同时自动清除命令队列。即使事务中的某些命令执行失败，其他命令仍会被正常执行。（包括出错命令之后的命令）
127.0.0.1:6379> multi
OK
127.0.0.1:6379> incr zhoucg
QUEUED
127.0.0.1:6379> incr y
QUEUED
127.0.0.1:6379> exec
1) (error) WRONGTYPE Operation against a key holding the wrong kind of value
2) (integer) 5
127.0.0.1:6379> 

**为什么redis的事务不支持会滚机制**

这个有点甩锅操作？

事实上Redis命令在事务执行时可能会失败，但仍会继续执行剩余命令而不是Rollback（事务回滚）。如果你使用过关系数据库，这种情况可能会让你感到很奇怪。然而针对这种情况具备很好的解释：

Redis命令可能会执行失败，仅仅是由于错误的语法被调用（命令排队时检测不出来的错误），或者使用错误的数据类型操作某个Key： 这意味着，实际上失败的命令都是编程错误造成的，都是开发中能够被检测出来的，生产环境中不应该存在。（这番话，彻底甩锅，“都是你们自己编程错误，与我们无关”。）
由于不必支持Rollback,Redis内部简洁并且更加高效。
“如果错误就是发生了呢？”这是一个反对Redis观点的争论。然而应该指出的是，通常情况下，回滚并不能挽救编程错误。鉴于没有人能够挽救程序员的错误，并且Redis命令失败所需的错误类型不太可能进入生产环境，所以我们选择了不支持错误回滚（Rollback）这种更简单快捷的方法。

**redis的事务是否具有隔离性**

Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。因此，Redis 的事务是总是带有隔离性的

#### redis的管道（pipline）

[**Redis 管道技术**](https://www.liangzl.com/get-article-detail-133400.html)

redis是一种基于客户端/服务断模式以及请求响应协议的/TCP服务，
客户端向服务端发送一个查询请求，并监听Socket返回，通常是以阻塞模式，等待服务端响应。
服务端处理命令，并将结果返回给客户端。

redis的管道技术是能够一次性的发送多个redis执行命令，并且最终一次性的读取所有服务端的响应
一次请求/响应服务器能实现处理新的请求即使旧的请求还未被响应。这样就可以将多个命令发送到服务器，而不用等待回复，最后在一个步骤中读取该答复。这就是管道（pipelining）

减少了传统型TCP请求响应的socker上的响应等待，

#### redis的缓存雪崩

缓存雪崩指得是缓存突然一次性大面积的失效，导致高并发都访问数据库，从而导致数据库的压力过大，从而导致崩掉

解决策略：
1，适当的调整合适的内存淘汰策略，避免大面积的缓存再同一个时间失效
2，增加redis集群的高可用

### Kafka

### Dubbo

### Zookeeper

### Netty

### Elasticsearch

### Spring

### Spring Boot

### Spring Cloud

### 微服务架构

#### 分布式事务

[分布式事务架构](http://www.tianshouzhi.com/api/tutorials/distributed_transaction/383)

分布式事务类型：

​			跨库事务

​			分库分表

​			微服务（SOA）：TCC两阶段提交：柔性分布式事务解决

DTP分布式事务模型（Distributed Transaction Processing: Reference Model）

 **应用程序(Application Program ，简称AP)：**用于定义事务边界(即定义事务的开始和结束)，并且在事务边界内对资源进行操作。

 **资源管理器(Resource Manager，简称RM)：**如数据库、文件系统等，并提供访问资源的方式。

 **事务管理器(Transaction Manager ，简称TM)：**负责分配事务唯一标识，监控事务的执行进度，并负责事务的提交、回滚等。

 **通信资源管理器(Communication Resource Manager，简称CRM)：**控制一个TM域(TM domain)内或者跨TM域的分布式应用之间的通信。

  **通信协议(Communication Protocol，简称CP)：**提供CRM提供的分布式应用节点之间的底层通信服务。



XA规范：

​		XA规范主要定义了RM和TM之间的协议（分布式事务模型DTP中定义了常用分布式事务模型的节点功能）

​		XA规范除了定义的RM-TM交互的接口(XA Interface)之外，还对两阶段提交协议进行了优化。 一些读者可能会误认为两阶段提交协议是在XA规范中提出来的。事实上： 两阶段协议(two-phase commit)是在OSI TP标准中提出的；在DTP参考模型(<<Distributed Transaction Processing: Reference Model>>)中，指定了全局事务的提交要使用two-phase commit协议；而XA规范(<< Distributed Transaction Processing: The XA Specification>>)只是定义了两阶段提交协议中需要使用到的接口，也就是上述提到的RM-TM交互的接口，因为两阶段提交过程中的参与方，只有TM和RMs。 

**XA规范对两阶段（2PC）提交进行了优化**：

两阶段的问题，和三阶段对应的优化点（2PC）（3PC）

两阶段提交（2PC）：prepare commit/cancel

三阶段提交（3PC）：canCommit/preCommit/doCommit



CAP理论：分布式系统

BASE:	BASE是Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性）三个短语的缩写。



在DTP模型中，Mysql只是属于RM（资源管理器），而一个完整的分布式事务中，一般会存在多个RM，由事务管理器TM来统一进行协调。因此，这里所说的mysql对XA分布式事务的支持，一般指的是单台mysql实例如何执行自己的事务分支。



**java事务API(JTA:Java Transaction API)**

[JTA规范](http://www.tianshouzhi.com/api/tutorials/distributed_transaction/385)

​			某种程度上，可以认为JTA规范事XA规范的java版，其把XA规范中规定的DTP模型交互接口抽象成Java接口中的方法，并规定每个方法要实现什么样的功能

![](image/JTA.png)

**事务管理器（TM）:**

​		 处于图中最为核心的位置，其他的事务参与者都是与事务管理器进行交互。事务管理器提供事务声明，事务资源管理，同步，事务上下文传播等功能。JTA规范定义了事务管理器与其他事务参与者交互的接口，而JTS规范定义了事务管理器的实现要求，因此我们看到事务管理器底层是基于JTS的。

**应用管理器：（application server)**

​		顾名思义，是应用程序运行的容器。JTA规范规定，事务管理器的功能应该由application server提供，如上图中的EJB Server。一些常见的其他web容器，如：jboss、weblogic、websphere等，都可以作为application server，这些web容器都实现了JTA规范。特别需要注意的是，并不是所有的web容器都实现了JTA规范，如tomcat并没有实现JTA规范，因此并不能提供事务管理器的功能。

**应用程序(application)：**

   简单来说，就是我们自己编写的应用，部署到了实现了JTA规范的application server中，之后我们就可以我们JTA规范中定义的UserTransaction类来声明一个分布式事务。通常情况下，application server为了简化开发者的工作量，并不一定要求开发者使用UserTransaction来声明一个事务，开发者可以在需要使用分布式事务的方法上添加一个注解，就像spring的声明式事务一样，来声明一个分布式事务。

  特别需要注意的是，JTA规范规定事务管理器的功能由application server提供。但是如果我们的应用不是一个web应用，而是一个本地应用，不需要被部署到application server中，无法使用application server提供的事务管理器功能。又或者我们使用的web容器并没有事务管理器的功能，如tomcat。对于这些情况，我们可以直接使用一些第三方的事务管理器类库，如JOTM和Atomikos。将事务管理器直接整合进应用中，不再依赖于application server。

**资源管理器(resource manager)：**

  理论上任何可以存储数据的软件，都可以认为是资源管理器RM。最典型的RM就是关系型数据库了，如mysql，另外一种比较常见的资源管理器是消息中间件，如ActiveMQ、RabbitMQ等， 这些都是真正的资源管理器。  

  事实上，将资源管理器(resource manager)称为资源适配器(resource adapter)似乎更为合适。因为在java程序中，我们都是通过client来于RM进行交互的，例如：我们通过mysql-connector-java-x.x.x.jar驱动包，获取Conn、执行sql，与mysql服务端进行通信；通过ActiveMQ、RabbitMQ等的客户端，来发送消息等。

  正常情况下，一个数据库驱动供应商只需要实现JDBC规范即可，一个消息中间件供应商只需要实现JMS规范即可。 而引入了分布式事务的概念后，DB、MQ等在DTP模型中的作用都是RM，二者是等价的，需要由TM统一进行协调。

   **为此，JTA规范定义了一个XAResource接口，其定义RM必须要提供给TM调用的一些方法。之后，不管这个RM是DB，还是MQ，TM并不关心，因为其操作的是XAResource接口。而其他规范(如JDBC、JMS)的实现者，同时也对此接口进行实现。如MysqlXAConnection，就实现了XAResource接口。**

#### 柔性事务 ：TCC两阶段补偿型

[柔性事务 ：TCC两阶段补偿型](http://www.tianshouzhi.com/api/tutorials/distributed_transaction/388)

**TCC（Try-Confirm-Cancel）的作用主要用来解决跨服务调用场景下的分布式事务问题**

TCC是Try-Confirm-Cancel的简称:

**Try阶段：**

  完成所有业务检查（一致性），预留业务资源(准隔离性)

  回顾上面航班预定案例的阶段1，机票就是业务资源，所有的资源提供者(航空公司)预留都成功，try阶段才算成功

**Confirm阶段：**

  确认执行业务操作，不做任何业务检查， 只使用Try阶段预留的业务资源。回顾上面航班预定案例的阶段2，美团APP确认两个航空公司机票都预留成功，因此向两个航空公司分别发送确认购买的请求。、

**Cancel阶段：**

   取消Try阶段预留的业务资源。回顾上面航班预定案例的阶段2，如果某个业务方的业务资源没有预留成功，则取消所有业务资源预留请求。 



TCC两阶段提交与XA两阶段提交的区别是：

​		**XA是资源层面的分布式事务，强一致性，在两阶段提交的整个过程中，一直会持有资源的锁。**	

​		**TCC是业务层面的分布式事务，最终一致性，不会一直持有资源的锁。**



为什么说TCC是补偿型事务：

​		"补偿是一个独立的支持ACID特性的本地事务，用于在逻辑上取消服务提供者上一个ACID事务造成的影响，对于一个长事务(long-running transaction)，与其实现一个巨大的分布式ACID事务，不如使用基于补偿性的方案，把每一次服务调用当做一个较短的本地ACID事务来处理，执行完就立即提交”。

   在这里，笔者理解为confirm和cancel就是补偿事务，用于取消try阶段本地事务造成的影响。因为第一阶段try只是预留资源，之后必须要明确的告诉服务提供者，这个资源你到底要不要，对应第二阶段的confirm/cancel。

  提示：读者现在应该明白为什么把TCC叫做两阶段补偿性事务了，提交过程分为2个阶段，第二阶段的confirm/cancel执行的事务属于补偿事务。 



